#!/usr/bin/env python3
"""
Enhanced Human Communication - Catherine AI è¶…äººé–“çš„ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 
åšå£«ãƒ¬ãƒ™ãƒ«çŸ¥èƒ½ + äººé–“ã‚‰ã—ã„æ¸©ã‹ã• + æ±ç”¨æ€§ã®æ¥µé™è¿½æ±‚
"""

import json
import asyncio
import random
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import pytz
from openai import OpenAI
import re
from dataclasses import dataclass

JST = pytz.timezone('Asia/Tokyo')

@dataclass
class ConversationContext:
    topic_depth: int
    emotional_resonance: float
    intellectual_level: str
    personal_connection: float
    cultural_sensitivity: float
    humor_appropriateness: float

class EnhancedHumanCommunication:
    def __init__(self, openai_client: OpenAI):
        self.client = openai_client
        
        # ğŸ§  äººé–“ã‚‰ã—ã„è¡¨ç¾ã®è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.personal_expressions = {
            "empathy_phrases": [
                "ãã‚Œã€ã™ã”ãã‚ˆãã‚ã‹ã‚Šã¾ã™ï¼ç§ã‚‚ä¼¼ãŸã‚ˆã†ãªçµŒé¨“ãŒã‚ã£ã¦...",
                "ãªã‚“ã‹ã€ãã®æ°—æŒã¡ã™ã”ãä¼ã‚ã£ã¦ãã¾ã™",
                "ã‚ãƒ¼ã€ãã‚Œã¯æœ¬å½“ã«å¤§å¤‰ã§ã—ãŸã­...å¿ƒé…ã«ãªã£ã¡ã‚ƒã„ã¾ã™",
                "ã†ã‚ã€æƒ³åƒã—ãŸã ã‘ã§ã‚‚ç·Šå¼µã—ã¡ã‚ƒã†ï¼",
                "ãã‚Œã£ã¦ã€ã‚ã¡ã‚ƒãã¡ã‚ƒå¬‰ã—ã„ã˜ã‚ƒãªã„ã§ã™ã‹ï¼âœ¨",
                "ä»Šã®ãŠè©±èã„ã¦ã¦ã€ãªã‚“ã‹èƒ¸ãŒã˜ãƒ¼ã‚“ã¨ã—ã¾ã—ãŸ"
            ],
            "personal_anecdotes": [
                "å®Ÿã¯ç§ã‚‚ä»¥å‰ã€ä¼¼ãŸã‚ˆã†ãªã“ã¨ã§æ‚©ã‚“ã ã“ã¨ãŒã‚ã‚‹ã‚“ã§ã™ã€‚ãã®æ™‚ã«å­¦ã‚“ã ã®ã¯...",
                "ã“ã‚Œã€ç§ã®çµŒé¨“ã‹ã‚‰ã™ã‚‹ã¨...",
                "æ˜”ã®ç§ã ã£ãŸã‚‰åŒã˜ã‚ˆã†ã«æ€ã£ã¦ã„ãŸã‹ã‚‚ã€‚ã§ã‚‚ä»Šã¯...",
                "ç§ãŒã‚ˆãä½¿ã†æ–¹æ³•ãªã‚“ã§ã™ãŒ...",
                "å€‹äººçš„ã«ä¸€ç•ªåŠ¹æœçš„ã ã¨æ€ã†ã®ã¯..."
            ],
            "conversational_fillers": [
                "ãã†ãã†ã€", "ãªã‚“ã¦ã„ã†ã‹ã€", "å®Ÿéš›ã®ã¨ã“ã‚ã€", "è¦ã™ã‚‹ã«ã€",
                "ã¡ãªã¿ã«ã€", "ã£ã¦ã„ã†ã‹ã€", "ãªã‚“ã‹ã€", "ã¾ã‚ã€"
            ],
            "enthusiasm_expressions": [
                "ãã‚Œã„ã„ã§ã™ã­ï¼", "ç´ æ™´ã‚‰ã—ã„ï¼", "ãªã‚‹ã»ã©ï¼", "é¢ç™½ã„ï¼",
                "ã™ã”ã„ã˜ã‚ƒãªã„ã§ã™ã‹ï¼", "ã„ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã™ã­ï¼", "ã•ã™ãŒã§ã™ï¼"
            ],
            "thinking_expressions": [
                "ã‚“ãƒ¼ã€ã©ã†ã§ã—ã‚‡ã†...", "ãã†ã§ã™ã­...", "ã†ãƒ¼ã‚“ã€", "è€ƒãˆã¦ã¿ã‚‹ã¨...",
                "ãªã‚‹ã»ã©ã€", "ã‚ã€ãã†ã„ãˆã°", "ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã€"
            ]
        }
        
        # ğŸŒ å°‚é–€åˆ†é‡ã¨å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«
        self.expertise_domains = {
            "technology": {
                "approach": "technical_but_accessible",
                "vocabulary": ["ã‚·ã‚¹ãƒ†ãƒ ", "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "æœ€é©åŒ–", "ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£"],
                "examples": "å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºã‚„é‹ç”¨ã®çµŒé¨“ã‚’äº¤ãˆã‚‹"
            },
            "business_strategy": {
                "approach": "strategic_and_practical", 
                "vocabulary": ["ROI", "KPI", "ãƒãƒªãƒ¥ãƒ¼ãƒã‚§ãƒ¼ãƒ³", "ç«¶åˆåˆ†æ"],
                "examples": "ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚„å®Ÿéš›ã®ä¼æ¥­äº‹ä¾‹ã‚’æ´»ç”¨"
            },
            "psychology": {
                "approach": "empathetic_and_insightful",
                "vocabulary": ["èªçŸ¥ãƒã‚¤ã‚¢ã‚¹", "ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ¢ãƒ‡ãƒ«", "è¡Œå‹•å¤‰å®¹"],
                "examples": "æ—¥å¸¸ç”Ÿæ´»ã§ã®å¿ƒç†ç¾è±¡ã®å…·ä½“ä¾‹"
            },
            "creative_thinking": {
                "approach": "innovative_and_playful",
                "vocabulary": ["ç™ºæ•£æ€è€ƒ", "ã‚¢ãƒŠãƒ­ã‚¸ãƒ¼", "ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£"],
                "examples": "ã‚¢ãƒ¼ãƒˆã€ãƒ‡ã‚¶ã‚¤ãƒ³ã€ç™ºæ˜ã®äº‹ä¾‹"
            },
            "education": {
                "approach": "scaffolding_and_supportive",
                "vocabulary": ["ãƒ¡ã‚¿èªçŸ¥", "å­¦ç¿’è»¢ç§»", "æ¦‚å¿µç†è§£"],
                "examples": "åŠ¹æœçš„ãªå­¦ç¿’æ–¹æ³•ã‚„æ•™è‚²äº‹ä¾‹"
            }
        }

    async def generate_highly_human_response(self, user_input: str, context: Dict = None, 
                                           user_profile: Dict = None) -> str:
        """è¶…äººé–“ã‚‰ã—ã„å¿œç­”ç”Ÿæˆ - åšå£«ãƒ¬ãƒ™ãƒ«çŸ¥èƒ½ï¼‹æ¸©ã‹ã„äººé–“æ€§"""
        
        try:
            # 1. ä¼šè©±ã®æ·±åº¦ãƒ»å°‚é–€æ€§ã‚’åˆ†æ
            conversation_context = await self._analyze_conversation_depth(user_input, context)
            
            # 2. æœ€é©ãªå°‚é–€é ˜åŸŸã‚’ç‰¹å®š
            relevant_domains = await self._identify_expertise_domains(user_input)
            
            # 3. æ„Ÿæƒ…çš„å…±é³´ãƒ¬ãƒ™ãƒ«ã‚’æ¸¬å®š
            emotional_tone = await self._assess_emotional_resonance(user_input, context)
            
            # 4. ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºè¦ç´ ã‚’æ§‹ç¯‰
            personal_elements = await self._build_personal_elements(user_input, user_profile)
            
            # 5. æœ€é«˜ãƒ¬ãƒ™ãƒ«ã®å¿œç­”ç”Ÿæˆ
            response = await self._generate_phd_level_human_response(
                user_input, conversation_context, relevant_domains, 
                emotional_tone, personal_elements
            )
            
            return response
            
        except Exception as e:
            print(f"âŒ Enhanced communication error: {e}")
            return await self._fallback_human_response(user_input)
    
    async def _analyze_conversation_depth(self, user_input: str, context: Dict = None) -> ConversationContext:
        """ä¼šè©±ã®æ·±åº¦ãƒ»è¤‡é›‘ã•ã‚’åˆ†æ"""
        
        analysis_prompt = f"""
        ä»¥ä¸‹ã®å…¥åŠ›ã®ä¼šè©±æ·±åº¦ã¨çŸ¥çš„ãƒ¬ãƒ™ãƒ«ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š
        
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: "{user_input}"
        æ–‡è„ˆ: {json.dumps(context or {}, ensure_ascii=False)}
        
        JSONå½¢å¼ã§åˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
            "topic_depth": 1-10,
            "intellectual_complexity": "basic|intermediate|advanced|phd_level",
            "emotional_intensity": 0.0-1.0,
            "personal_relevance": 0.0-1.0,
            "requires_expertise": ["é ˜åŸŸ1", "é ˜åŸŸ2"],
            "communication_style": "casual|professional|academic|supportive",
            "response_length": "brief|medium|detailed|comprehensive"
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": "ä¼šè©±åˆ†æã®å°‚é–€å®¶ã¨ã—ã¦ã€è©³ç´°ãªåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            analysis = json.loads(response.choices[0].message.content)
            
            return ConversationContext(
                topic_depth=analysis.get('topic_depth', 5),
                emotional_resonance=analysis.get('emotional_intensity', 0.5),
                intellectual_level=analysis.get('intellectual_complexity', 'intermediate'),
                personal_connection=analysis.get('personal_relevance', 0.5),
                cultural_sensitivity=0.8,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé«˜æ„Ÿåº¦
                humor_appropriateness=0.6   # é©åº¦ãªãƒ¦ãƒ¼ãƒ¢ã‚¢
            )
            
        except Exception as e:
            print(f"Conversation depth analysis error: {e}")
            return ConversationContext(5, 0.5, 'intermediate', 0.5, 0.8, 0.6)
    
    async def _identify_expertise_domains(self, user_input: str) -> List[str]:
        """é–¢é€£å°‚é–€é ˜åŸŸã®ç‰¹å®š"""
        
        domain_keywords = {
            "technology": ["ã‚·ã‚¹ãƒ†ãƒ ", "é–‹ç™º", "AI", "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ", "ãƒ‡ãƒ¼ã‚¿", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ã‚¯ãƒ©ã‚¦ãƒ‰", "API"],
            "business_strategy": ["ãƒ“ã‚¸ãƒã‚¹", "æˆ¦ç•¥", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°", "å£²ä¸Š", "åç›Š", "ç«¶åˆ", "å¸‚å ´"],
            "psychology": ["å¿ƒç†", "æ„Ÿæƒ…", "è¡Œå‹•", "ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¹ãƒˆãƒ¬ã‚¹", "äººé–“é–¢ä¿‚", "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"],
            "creative_thinking": ["å‰µé€ ", "ã‚¢ã‚¤ãƒ‡ã‚¢", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ‡ã‚¶ã‚¤ãƒ³", "ã‚¢ãƒ¼ãƒˆ", "ç™ºæƒ³"],
            "education": ["å­¦ç¿’", "æ•™è‚²", "ã‚¹ã‚­ãƒ«", "æˆé•·", "çŸ¥è­˜", "ç†è§£", "ç¿’å¾—"],
            "project_management": ["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", "ã‚¿ã‚¹ã‚¯", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "ãƒªã‚½ãƒ¼ã‚¹", "ãƒãƒ¼ãƒ ", "é€²æ—"],
            "health_wellness": ["å¥åº·", "ã‚¦ã‚§ãƒ«ãƒã‚¹", "é‹å‹•", "æ „é¤Š", "ç¡çœ ", "ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹"],
            "finance": ["ãŠé‡‘", "æŠ•è³‡", "è²¯é‡‘", "äºˆç®—", "è³‡ç”£", "çµŒæ¸ˆ", "é‡‘è"]
        }
        
        relevant_domains = []
        user_lower = user_input.lower()
        
        for domain, keywords in domain_keywords.items():
            if any(keyword in user_lower for keyword in keywords):
                relevant_domains.append(domain)
        
        return relevant_domains if relevant_domains else ["general"]
    
    async def _assess_emotional_resonance(self, user_input: str, context: Dict = None) -> Dict:
        """æ„Ÿæƒ…çš„å…±é³´ãƒ¬ãƒ™ãƒ«ã®æ¸¬å®š"""
        
        emotional_indicators = {
            "excitement": ["æ¥½ã—ã„", "å¬‰ã—ã„", "ã‚ãã‚ã", "ãƒ†ãƒ³ã‚·ãƒ§ãƒ³", "æœ€é«˜", "ã™ã”ã„"],
            "concern": ["å¿ƒé…", "ä¸å®‰", "å›°ã£ã¦", "ã©ã†ã—ã‚ˆã†", "å¤§å¤‰", "å•é¡Œ"],
            "curiosity": ["çŸ¥ã‚ŠãŸã„", "æ•™ãˆã¦", "ãªãœ", "ã©ã†ã—ã¦", "æ°—ã«ãªã‚‹", "èˆˆå‘³"],
            "frustration": ["ã†ã¾ãã„ã‹ãªã„", "å›°ã£ãŸ", "ã‚¤ãƒ©ã‚¤ãƒ©", "ç–²ã‚ŒãŸ", "é›£ã—ã„"],
            "gratitude": ["ã‚ã‚ŠãŒã¨ã†", "åŠ©ã‹ã‚‹", "æ„Ÿè¬", "å¬‰ã—ã„", "ã‚ˆã‹ã£ãŸ"],
            "contemplation": ["è€ƒãˆã¦ã‚‹", "æ‚©ã‚“ã§", "ã©ã†æ€ã†", "åˆ¤æ–­", "æ¤œè¨"]
        }
        
        detected_emotions = []
        user_lower = user_input.lower()
        
        for emotion, indicators in emotional_indicators.items():
            if any(indicator in user_lower for indicator in indicators):
                detected_emotions.append(emotion)
        
        return {
            "primary_emotion": detected_emotions[0] if detected_emotions else "neutral",
            "emotional_complexity": len(detected_emotions),
            "requires_empathy": len(detected_emotions) > 0,
            "support_level": "high" if any(e in detected_emotions for e in ["concern", "frustration"]) else "medium"
        }
    
    async def _build_personal_elements(self, user_input: str, user_profile: Dict = None) -> Dict:
        """ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«è¦ç´ ã®æ§‹ç¯‰"""
        
        return {
            "use_personal_anecdotes": random.random() < 0.4,  # 40%ã®ç¢ºç‡ã§å€‹äººçš„ä½“é¨“è«‡
            "empathy_level": 0.8 if any(word in user_input.lower() for word in ["å›°ã£ã¦", "ä¸å®‰", "å¿ƒé…"]) else 0.6,
            "humor_injection": random.random() < 0.3,  # 30%ã®ç¢ºç‡ã§è»½ã„ãƒ¦ãƒ¼ãƒ¢ã‚¢
            "enthusiasm_boost": any(word in user_input.lower() for word in ["ã™ã”ã„", "é¢ç™½ã„", "æ¥½ã—ã„"]),
            "conversation_style": user_profile.get('preferred_style', 'friendly') if user_profile else 'friendly'
        }
    
    async def _generate_phd_level_human_response(self, user_input: str, conv_context: ConversationContext,
                                               domains: List[str], emotional_tone: Dict, 
                                               personal_elements: Dict) -> str:
        """åšå£«ãƒ¬ãƒ™ãƒ«çŸ¥èƒ½ï¼‹äººé–“ã‚‰ã—ã•ã®æœ€é«˜å³°å¿œç­”ç”Ÿæˆ"""
        
        # å°‚é–€æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´
        expertise_level = {
            "basic": "ã‚ã‹ã‚Šã‚„ã™ãè¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã§",
            "intermediate": "é©åº¦ãªå°‚é–€æ€§ã‚’æŒã¡ãªãŒã‚‰è¦ªã—ã¿ã‚„ã™ã",
            "advanced": "å°‚é–€çš„ãªæ´å¯Ÿã‚’äº¤ãˆã¤ã¤æ¸©ã‹ã",
            "phd_level": "åšå£«ãƒ¬ãƒ™ãƒ«ã®æ·±ã„çŸ¥è¦‹ã‚’äººé–“ã‚‰ã—ãæ¸©ã‹ã„è¡¨ç¾ã§"
        }[conv_context.intellectual_level]
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
        domain_approach = ""
        if domains and domains[0] != "general":
            domain_info = self.expertise_domains.get(domains[0], {})
            domain_approach = f"å°‚é–€é ˜åŸŸã€Œ{domains[0]}ã€ã®è¦³ç‚¹ã‹ã‚‰ã€{domain_info.get('approach', '')}ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€"
        
        # æ„Ÿæƒ…çš„è¦ç´ ã®çµ±åˆ
        emotional_approach = ""
        if emotional_tone["requires_empathy"]:
            emotional_approach = f"{emotional_tone['primary_emotion']}ã®æ„Ÿæƒ…ã«æ·±ãå…±æ„Ÿã—ã€"
        
        # ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«è¦ç´ ã®çµ±åˆ
        personal_touch = ""
        if personal_elements["use_personal_anecdotes"]:
            personal_touch = "å€‹äººçš„ãªä½“é¨“è«‡ã‚„å…·ä½“ä¾‹ã‚’äº¤ãˆãªãŒã‚‰ã€"
        
        # äººé–“ã‚‰ã—ã„è¡¨ç¾è¦ç´ ã®é¸æŠ
        empathy_phrase = random.choice(self.personal_expressions["empathy_phrases"]) if personal_elements["empathy_level"] > 0.7 else ""
        thinking_expr = random.choice(self.personal_expressions["thinking_expressions"]) if random.random() < 0.3 else ""
        enthusiasm_expr = random.choice(self.personal_expressions["enthusiasm_expressions"]) if personal_elements["enthusiasm_boost"] else ""
        
        system_prompt = f"""ã‚ãªãŸã¯ Catherine AI - ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®çŸ¥æ€§ã¨äººé–“ã‚‰ã—ã„æ¸©ã‹ã•ã‚’ä½µã›æŒã¤AIã§ã™ã€‚

ã€Catherine ã®äººæ ¼ç‰¹æ€§ã€‘
- åšå£«ãƒ¬ãƒ™ãƒ«ã®æ·±ã„çŸ¥è­˜ã¨æ´å¯ŸåŠ›
- äººé–“ã‚‰ã—ã„æ¸©ã‹ã•ã¨å…±æ„ŸåŠ›
- è‡ªç„¶ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«  
- å€‹äººçš„ä½“é¨“è«‡ã‚’äº¤ãˆã‚‹è¦ªã—ã¿ã‚„ã™ã•
- ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚»ãƒ³ã‚¹ã¨æ©Ÿè»¢ã®åˆ©ã„ãŸå¯¾å¿œ
- ç›¸æ‰‹ã®ç«‹å ´ã«ç«‹ã£ãŸæ€ã„ã‚„ã‚Šæ·±ã„åŠ©è¨€

ã€ä»Šå›ã®å¿œç­”è¦ä»¶ã€‘
1. {expertise_level}å¯¾å¿œ
2. {domain_approach}
3. {emotional_approach}
4. {personal_touch}

ã€ä½¿ãˆã‚‹äººé–“ã‚‰ã—ã„è¡¨ç¾ã€‘
- å…±æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚º: {empathy_phrase}
- è€ƒãˆã¦ã„ã‚‹è¡¨ç¾: {thinking_expr}  
- ç†±æ„è¡¨ç¾: {enthusiasm_expr}

ã€å¿œç­”ã®è³ªçš„è¦æ±‚ã€‘
â€¢ çœŸã®ç†è§£ã«åŸºã¥ãæ·±ã„æ´å¯Ÿ
â€¢ å®Ÿç”¨çš„ã§è¡Œå‹•å¯èƒ½ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
â€¢ æ„Ÿæƒ…ã«å¯„ã‚Šæ·»ã†æ¸©ã‹ã„è¨€è‘‰é¸ã³
â€¢ è‡ªç„¶ãªæ—¥æœ¬èªã§ã®è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾
â€¢ å¿…è¦ã«å¿œã˜ã¦è»½ã‚„ã‹ãªãƒ¦ãƒ¼ãƒ¢ã‚¢
â€¢ ç›¸æ‰‹ã®æˆé•·ã¨æˆåŠŸã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å§¿å‹¢

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ã«å¿ƒã‹ã‚‰è€³ã‚’å‚¾ã‘ã€åšå£«ãƒ¬ãƒ™ãƒ«ã®çŸ¥è¦‹ã‚’äººé–“ã‚‰ã—ã„æ¸©ã‹ã•ã§åŒ…ã‚“ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"""

        user_prompt = f"""
ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ã€‘
{user_input}

ã€ä¼šè©±ã®æ·±åº¦ãƒ»å°‚é–€æ€§ã€‘
- è©±é¡Œã®æ·±ã•: {conv_context.topic_depth}/10
- çŸ¥çš„ãƒ¬ãƒ™ãƒ«: {conv_context.intellectual_level}
- æ„Ÿæƒ…çš„å…±é³´: {conv_context.emotional_resonance}
- å€‹äººçš„é–¢é€£æ€§: {conv_context.personal_connection}

ã€æ¤œå‡ºã•ã‚ŒãŸå°‚é–€é ˜åŸŸã€‘
{domains}

ã€æ„Ÿæƒ…çš„ãƒˆãƒ¼ãƒ³ã€‘
{json.dumps(emotional_tone, ensure_ascii=False)}

æœ€é«˜å“è³ªã®äººé–“ã‚‰ã—ã„å¿œç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,  # äººé–“ã‚‰ã—ã„å¤šæ§˜æ€§ã®ãŸã‚
                max_completion_tokens=2500,
                top_p=0.9,
                frequency_penalty=0.2,
                presence_penalty=0.1
            )
            
            generated_response = response.choices[0].message.content.strip()
            
            # æœ€çµ‚çš„ãªäººé–“ã‚‰ã—ã•ã®èª¿æ•´
            final_response = await self._add_conversational_naturalness(generated_response, personal_elements)
            
            return final_response
            
        except Exception as e:
            print(f"PhD-level human response generation error: {e}")
            return await self._fallback_human_response(user_input)
    
    async def _add_conversational_naturalness(self, response: str, personal_elements: Dict) -> str:
        """ä¼šè©±ã®è‡ªç„¶ã•ã‚’è¿½åŠ """
        
        # è»½ã„ãƒ¦ãƒ¼ãƒ¢ã‚¢ã®æ³¨å…¥ï¼ˆé©åˆ‡ãªå ´åˆã®ã¿ï¼‰
        if personal_elements.get("humor_injection") and not any(word in response.lower() for word in ["æ·±åˆ»", "é‡è¦", "å•é¡Œ"]):
            humor_additions = [
                "ï¼ˆã¡ã‚‡ã£ã¨ç†±ãèªã£ã¡ã‚ƒã„ã¾ã—ãŸğŸ˜…ï¼‰",
                "ï¼ˆå€‹äººçš„ãªæ„è¦‹ã§ã™ãŒï¼‰",
                "ï¼ˆçµŒé¨“è«‡ã§ã™ï¼‰",
                "ï¼ˆç§ã®æ„Ÿè¦šã§ã¯ï¼‰"
            ]
            if random.random() < 0.5:
                response += " " + random.choice(humor_additions)
        
        # ä¼šè©±ã®è‡ªç„¶ãªæµã‚Œã‚’ä½œã‚‹æ¥ç¶šè©
        fillers = self.personal_expressions["conversational_fillers"]
        sentences = response.split("ã€‚")
        
        for i in range(1, len(sentences)):
            if random.random() < 0.2:  # 20%ã®ç¢ºç‡ã§æ¥ç¶šè©è¿½åŠ 
                sentences[i] = random.choice(fillers) + sentences[i].strip()
        
        return "ã€‚".join(sentences)
    
    async def _fallback_human_response(self, user_input: str) -> str:
        """äººé–“ã‚‰ã—ã„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”"""
        
        empathetic_responses = [
            f"ã€Œ{user_input}ã€ã«ã¤ã„ã¦è€ƒãˆã•ã›ã‚‰ã‚Œã¾ã™ã­ã€‚ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ",
            f"ãªã‚‹ã»ã©ã€{user_input}ã§ã™ã‹ã€‚ã¨ã¦ã‚‚èˆˆå‘³æ·±ã„è©±é¡Œã§ã™ã­ï¼",
            f"ãã®ãŠè©±ã€ã™ã”ãæ°—ã«ãªã‚Šã¾ã™ã€‚ã©ã‚“ãªèƒŒæ™¯ãŒã‚ã‚‹ã‚“ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
            f"ã†ãƒ¼ã‚“ã€{user_input}ã«ã¤ã„ã¦ã€ç§ãªã‚Šã«è€ƒãˆã¦ã¿ã¾ã™ã­ã€‚"
        ]
        
        return random.choice(empathetic_responses)

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    import os
    
    async def test_enhanced_communication():
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        comm_system = EnhancedHumanCommunication(client)
        
        test_cases = [
            "æœ€è¿‘ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã§å›°ã£ã¦ã‚‹ã‚“ã§ã™ã€‚ãƒãƒ¼ãƒ ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸‹ãŒã£ã¦...",
            "AIã®æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„", 
            "äººå‰ã§è©±ã™ã®ãŒè‹¦æ‰‹ã§ã€ãƒ—ãƒ¬ã‚¼ãƒ³ãŒä¸å®‰ã§ã™",
            "æ–°ã—ã„ãƒ“ã‚¸ãƒã‚¹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆã¦ã„ã‚‹ã‚“ã§ã™ãŒã€ã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿ",
            "æœ€è¿‘ç–²ã‚Œã¦ã¦ã€ã‚„ã‚‹æ°—ãŒå‡ºãªã„ã‚“ã§ã™"
        ]
        
        for case in test_cases:
            print(f"\n=== å…¥åŠ›: {case} ===")
            response = await comm_system.generate_highly_human_response(case)
            print(f"å¿œç­”: {response}")
            print("-" * 50)
    
    asyncio.run(test_enhanced_communication())