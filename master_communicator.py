#!/usr/bin/env python3
"""
Master Communicator - Catherine AI è¶…é«˜åº¦ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¡“ã‚·ã‚¹ãƒ†ãƒ 
ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®èª¬æ˜åŠ›ãƒ»è³ªå•æŠ€è¡“ãƒ»å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ
"""

import json
import asyncio
import random
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from openai import OpenAI
import re
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class CommunicationContext:
    audience_level: str          # beginner, intermediate, expert, mixed
    communication_goal: str      # inform, persuade, engage, support, teach
    emotional_state: str         # receptive, defensive, confused, excited, neutral
    time_constraints: str        # urgent, normal, relaxed, none
    relationship_stage: str      # new, developing, established, deep
    cultural_context: str        # formal, casual, business, academic, personal

@dataclass
class ExplanationStrategy:
    approach: str
    structure: List[str]
    examples_needed: int
    visual_aids: bool
    interaction_points: List[str]
    complexity_gradation: List[str]

class MasterCommunicator:
    def __init__(self, openai_client: OpenAI):
        self.client = openai_client
        
        # ğŸ¯ èª¬æ˜æŠ€è¡“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆ
        self.explanation_techniques = {
            "layered_explanation": {
                "description": "æ®µéšçš„è©³ç´°åŒ–ã«ã‚ˆã‚‹èª¬æ˜",
                "structure": ["æ¦‚è¦", "è©³ç´°1", "è©³ç´°2", "çµ±åˆ"],
                "use_cases": ["è¤‡é›‘ãªæ¦‚å¿µ", "æŠ€è¡“çš„å†…å®¹", "æ®µéšçš„ç†è§£"]
            },
            "analogy_method": {
                "description": "é¡æ¨ãƒ»æ¯”å–©ã«ã‚ˆã‚‹èª¬æ˜",
                "structure": ["é¦´æŸ“ã¿ã‚ã‚‹ä¾‹", "é¡ä¼¼ç‚¹", "ç›¸é•ç‚¹", "å¿œç”¨"],
                "use_cases": ["æŠ½è±¡æ¦‚å¿µ", "æ–°ã—ã„æŠ€è¡“", "ç†è§£ä¿ƒé€²"]
            },
            "story_narrative": {
                "description": "ç‰©èªå½¢å¼ã«ã‚ˆã‚‹èª¬æ˜",
                "structure": ["è¨­å®š", "èª²é¡Œ", "è§£æ±ºéç¨‹", "çµè«–"],
                "use_cases": ["æ„Ÿæƒ…ç§»å…¥", "è¨˜æ†¶å®šç€", "èˆˆå‘³å–šèµ·"]
            },
            "problem_solution": {
                "description": "å•é¡Œè§£æ±ºå‹èª¬æ˜",
                "structure": ["å•é¡Œæç¤º", "åˆ†æ", "è§£æ±ºç­–", "åŠ¹æœ"],
                "use_cases": ["å®Ÿè·µçš„å†…å®¹", "èª²é¡Œè§£æ±º", "å‹•æ©Ÿä»˜ã‘"]
            },
            "socratic_dialogue": {
                "description": "å¯¾è©±å‹èª¬æ˜",
                "structure": ["è³ªå•", "æ€è€ƒèª˜å°", "æ°—ã¥ã", "ç¢ºèª"],
                "use_cases": ["èƒ½å‹•çš„å­¦ç¿’", "æ‰¹åˆ¤çš„æ€è€ƒ", "æ·±ã„ç†è§£"]
            }
        }
        
        # ğŸ¤” è³ªå•æŠ€è¡“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒ„ãƒ¼ãƒ«
        self.questioning_techniques = {
            "clarifying_questions": {
                "purpose": "ç†è§£ã®æ˜ç¢ºåŒ–",
                "examples": [
                    "ã¤ã¾ã‚Šã€{}ã¨ã„ã†ã“ã¨ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
                    "{}ã«ã¤ã„ã¦ã€ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ",
                    "ãã‚Œã¯{}ã¨ã„ã†æ„å‘³ã§æ‰ãˆã¦è‰¯ã„ã§ã™ã‹ï¼Ÿ"
                ]
            },
            "probing_questions": {
                "purpose": "æ·±ã„æ¢æ±‚",
                "examples": [
                    "ãã‚Œã¯ãªãœã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ",
                    "ä»–ã«ã©ã‚“ãªå¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã§ã—ã‚‡ã†ï¼Ÿ",
                    "ã‚‚ã—ãã†ã§ãªã„ã¨ã—ãŸã‚‰ã€ã©ã†ãªã‚Šã¾ã™ã‹ï¼Ÿ"
                ]
            },
            "hypothetical_questions": {
                "purpose": "æ€è€ƒæ‹¡å¼µ",
                "examples": [
                    "ã‚‚ã—{}ã ã£ãŸã‚‰ã€ã©ã†ã—ã¾ã™ã‹ï¼Ÿ",
                    "ç†æƒ³çš„ãªçŠ¶æ³ã§ã¯ã€ä½•ãŒèµ·ã“ã‚‹ã§ã—ã‚‡ã†ï¼Ÿ",
                    "é€†ã®ç«‹å ´ã ã£ãŸã‚‰ã€ã©ã†è€ƒãˆã¾ã™ã‹ï¼Ÿ"
                ]
            },
            "reflective_questions": {
                "purpose": "å†…çœä¿ƒé€²",
                "examples": [
                    "ã“ã‚Œã¾ã§ã®çµŒé¨“ã‹ã‚‰ã€ã©ã†æ„Ÿã˜ã¾ã™ã‹ï¼Ÿ",
                    "ã‚ãªãŸã«ã¨ã£ã¦æœ€ã‚‚é‡è¦ãªã®ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                    "ã“ã®ä»¶ã«ã¤ã„ã¦ã€ã©ã‚“ãªæ„Ÿæƒ…ã‚’æŠ±ã„ã¦ã„ã¾ã™ã‹ï¼Ÿ"
                ]
            },
            "strategic_questions": {
                "purpose": "æˆ¦ç•¥çš„æ€è€ƒ",
                "examples": [
                    "é•·æœŸçš„ã«è¦‹ã‚‹ã¨ã€ã©ã‚“ãªå½±éŸ¿ãŒã‚ã‚Šãã†ã§ã™ã‹ï¼Ÿ",
                    "ã“ã®æ±ºå®šã®ãƒªã‚¹ã‚¯ã¨ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã—ã‚‡ã†ï¼Ÿ",
                    "ä»–ã®ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¯ã©ã†åå¿œã™ã‚‹ã§ã—ã‚‡ã†ï¼Ÿ"
                ]
            }
        }
        
        # ğŸ’¬ å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆæŠ€è¡“
        self.dialogue_management = {
            "active_listening": {
                "techniques": ["è¦ç´„ãƒ»ç¢ºèª", "æ„Ÿæƒ…ã®åæ˜ ", "éè¨€èªæƒ…å ±ã®èª­å–ã‚Š"],
                "responses": ["ãã†ãŠã£ã—ã‚ƒã‚‹ã®ã¯", "ã¤ã¾ã‚ŠãŠæ°—æŒã¡ã¨ã—ã¦ã¯", "ã¨ã„ã†ã“ã¨ã¯"]
            },
            "rapport_building": {
                "techniques": ["å…±é€šç‚¹ç™ºè¦‹", "é©åˆ‡ãªè‡ªå·±é–‹ç¤º", "ãƒšãƒ¼ã‚·ãƒ³ã‚°ãƒ»ãƒãƒƒãƒãƒ³ã‚°"],
                "responses": ["ç§ã‚‚åŒã˜ã‚ˆã†ãªçµŒé¨“ãŒ", "ãã‚Œã™ã”ãã‚ã‹ã‚Šã¾ã™", "ãªã‚‹ã»ã©ã€ç¢ºã‹ã«"]
            },
            "conflict_resolution": {
                "techniques": ["åŒæ–¹ã®ç«‹å ´ç†è§£", "å…±é€šç›®æ¨™ã®ç¢ºèª", "win-winã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³"],
                "responses": ["ä¸¡æ–¹ã®è¦–ç‚¹ã§è¦‹ã‚‹ã¨", "å…±é€šã®ç›®æ¨™ã¯", "ã©ã¡ã‚‰ã«ã¨ã£ã¦ã‚‚è‰¯ã„æ–¹æ³•ã¯"]
            },
            "influence_persuasion": {
                "techniques": ["è«–ç†çš„æ ¹æ‹ ", "æ„Ÿæƒ…çš„ã‚¢ãƒ”ãƒ¼ãƒ«", "æ¨©å¨ãƒ»ä¿¡é ¼æ€§", "ç¤¾ä¼šçš„è¨¼æ˜"],
                "responses": ["ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ã‚‹ã¨", "ãŠæ°—æŒã¡ã‚’è€ƒãˆã‚‹ã¨", "å°‚é–€å®¶ã«ã‚ˆã‚‹ã¨", "å¤šãã®æ–¹ãŒ"]
            }
        }
    
    async def analyze_communication_context(self, user_input: str, conversation_history: List[Dict] = None,
                                          user_profile: Dict = None) -> CommunicationContext:
        """ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆã®è©³ç´°åˆ†æ"""
        
        context_prompt = f"""
        ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ï¼š
        
        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã€‘{user_input}
        ã€ä¼šè©±å±¥æ­´ã€‘{json.dumps(conversation_history[-3:] if conversation_history else [], ensure_ascii=False)}
        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€‘{json.dumps(user_profile or {}, ensure_ascii=False)}
        
        ä»¥ä¸‹ã®JSONå½¢å¼ã§æ–‡è„ˆåˆ†æã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        
        {{
            "audience_level": "beginner|intermediate|expert|mixed",
            "communication_goal": "inform|persuade|engage|support|teach|explore",
            "emotional_state": "receptive|defensive|confused|excited|frustrated|curious|neutral",
            "urgency_level": "immediate|high|normal|low",
            "relationship_stage": "new|developing|established|deep",
            "formality_level": "very_formal|formal|semi_formal|casual|very_casual",
            "cultural_sensitivity": 0.0-1.0,
            "information_density": "high|medium|low",
            "interaction_preference": "dialogue|explanation|guidance|exploration",
            "attention_span": "short|medium|long|variable",
            "learning_style": "visual|auditory|kinesthetic|reading|multimodal",
            "decision_readiness": 0.0-1.0,
            "trust_level": 0.0-1.0,
            "expertise_areas": ["é ˜åŸŸ1", "é ˜åŸŸ2"],
            "communication_barriers": ["éšœå£1", "éšœå£2"],
            "optimal_approach": "æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚æ–‡è„ˆã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": context_prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            analysis = json.loads(response.choices[0].message.content)
            
            return CommunicationContext(
                audience_level=analysis.get('audience_level', 'intermediate'),
                communication_goal=analysis.get('communication_goal', 'inform'),
                emotional_state=analysis.get('emotional_state', 'neutral'),
                time_constraints=analysis.get('urgency_level', 'normal'),
                relationship_stage=analysis.get('relationship_stage', 'developing'),
                cultural_context=analysis.get('formality_level', 'semi_formal')
            )
            
        except Exception as e:
            print(f"Communication context analysis error: {e}")
            return CommunicationContext('intermediate', 'inform', 'neutral', 'normal', 'developing', 'semi_formal')
    
    async def design_optimal_explanation(self, topic: str, context: CommunicationContext,
                                       complexity_level: int = 5) -> ExplanationStrategy:
        """æœ€é©èª¬æ˜æˆ¦ç•¥ã®è¨­è¨ˆ"""
        
        # æ–‡è„ˆã«åŸºã¥ãèª¬æ˜æŠ€è¡“ã®é¸æŠ
        if context.audience_level == 'beginner':
            primary_technique = 'analogy_method'
        elif context.communication_goal == 'engage':
            primary_technique = 'story_narrative'
        elif context.emotional_state in ['confused', 'frustrated']:
            primary_technique = 'layered_explanation'
        elif context.audience_level == 'expert':
            primary_technique = 'problem_solution'
        else:
            primary_technique = 'socratic_dialogue'
        
        technique_info = self.explanation_techniques[primary_technique]
        
        strategy_prompt = f"""
        ä»¥ä¸‹ã®æ¡ä»¶ã«åŸºã¥ã„ã¦ã€æœ€é©ãªèª¬æ˜æˆ¦ç•¥ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ï¼š
        
        ã€ãƒˆãƒ”ãƒƒã‚¯ã€‘{topic}
        ã€é¸æŠæŠ€è¡“ã€‘{primary_technique}: {technique_info['description']}
        ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆã€‘{context.__dict__}
        ã€è¤‡é›‘åº¦ã€‘{complexity_level}/10
        
        ä»¥ä¸‹ã®JSONå½¢å¼ã§è©³ç´°æˆ¦ç•¥ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        
        {{
            "explanation_structure": [
                {{
                    "section": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³å",
                    "content_type": "æ¦‚å¿µ|ä¾‹ç¤º|æ¯”è¼ƒ|å®Ÿæ¼”|è³ªå•",
                    "duration_estimate": "æ™‚é–“è¦‹ç©ã‚‚ã‚Š",
                    "interaction_points": ["ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³1", "ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³2"],
                    "difficulty_level": 1-10
                }}
            ],
            "examples_strategy": {{
                "analogy_examples": ["é¡æ¨ä¾‹1", "é¡æ¨ä¾‹2"],
                "concrete_examples": ["å…·ä½“ä¾‹1", "å…·ä½“ä¾‹2"],
                "counter_examples": ["åä¾‹1", "åä¾‹2"]
            }},
            "visual_aids": {{
                "diagrams_needed": ["å›³è¡¨1", "å›³è¡¨2"],
                "metaphors": ["æ¯”å–©1", "æ¯”å–©2"],
                "storytelling_elements": ["è¦ç´ 1", "è¦ç´ 2"]
            }},
            "interaction_design": {{
                "check_points": ["ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ1", "ãƒã‚¤ãƒ³ãƒˆ2"],
                "questions_to_ask": ["è³ªå•1", "è³ªå•2"],
                "activities": ["æ´»å‹•1", "æ´»å‹•2"]
            }},
            "adaptation_triggers": {{
                "confusion_signals": ["æ··ä¹±ã‚µã‚¤ãƒ³1", "ã‚µã‚¤ãƒ³2"],
                "engagement_drop": ["é–¢å¿ƒä½ä¸‹ã‚µã‚¤ãƒ³1", "ã‚µã‚¤ãƒ³2"],
                "comprehension_check": ["ç†è§£ç¢ºèªæ–¹æ³•1", "æ–¹æ³•2"]
            }}
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯èª¬æ˜è¨­è¨ˆã®å°‚é–€å®¶ã§ã™ã€‚æœ€é©ã§åŠ¹æœçš„ãªèª¬æ˜æˆ¦ç•¥ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": strategy_prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            strategy_data = json.loads(response.choices[0].message.content)
            
            return ExplanationStrategy(
                approach=primary_technique,
                structure=[section.get('section', '') for section in strategy_data.get('explanation_structure', [])],
                examples_needed=len(strategy_data.get('examples_strategy', {}).get('concrete_examples', [])),
                visual_aids=len(strategy_data.get('visual_aids', {}).get('diagrams_needed', [])) > 0,
                interaction_points=strategy_data.get('interaction_design', {}).get('questions_to_ask', []),
                complexity_gradation=[str(section.get('difficulty_level', 5)) for section in strategy_data.get('explanation_structure', [])]
            )
            
        except Exception as e:
            print(f"Explanation strategy design error: {e}")
            return ExplanationStrategy('layered_explanation', ['æ¦‚è¦', 'è©³ç´°', 'çµ±åˆ'], 2, False, ['ç†è§£åº¦ç¢ºèª'], ['5'])
    
    async def generate_strategic_questions(self, topic: str, context: CommunicationContext,
                                         conversation_stage: str = 'exploration') -> List[str]:
        """æˆ¦ç•¥çš„è³ªå•ã®ç”Ÿæˆ"""
        
        # ä¼šè©±æ®µéšã¨ç›®æ¨™ã«åŸºã¥ãè³ªå•ã‚¿ã‚¤ãƒ—ã®é¸æŠ
        if conversation_stage == 'exploration':
            primary_types = ['clarifying_questions', 'probing_questions']
        elif conversation_stage == 'deepening':
            primary_types = ['probing_questions', 'reflective_questions']
        elif conversation_stage == 'decision':
            primary_types = ['strategic_questions', 'hypothetical_questions']
        else:
            primary_types = ['clarifying_questions', 'strategic_questions']
        
        questions_prompt = f"""
        ä»¥ä¸‹ã®æ–‡è„ˆã§æœ€ã‚‚åŠ¹æœçš„ãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
        
        ã€ãƒˆãƒ”ãƒƒã‚¯ã€‘{topic}
        ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆã€‘{context.__dict__}
        ã€ä¼šè©±æ®µéšã€‘{conversation_stage}
        ã€å„ªå…ˆè³ªå•ã‚¿ã‚¤ãƒ—ã€‘{primary_types}
        
        ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã§è³ªå•ã‚’ç”Ÿæˆã—ã€JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        
        {{
            "opening_questions": [
                {{
                    "question": "å°å…¥è³ªå•",
                    "purpose": "ç›®çš„",
                    "expected_response": "æœŸå¾…ã•ã‚Œã‚‹å¿œç­”ã‚¿ã‚¤ãƒ—"
                }}
            ],
            "deepening_questions": [
                {{
                    "question": "æ·±æ˜ã‚Šè³ªå•", 
                    "purpose": "ç›®çš„",
                    "follow_up": "ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•"
                }}
            ],
            "clarifying_questions": [
                {{
                    "question": "æ˜ç¢ºåŒ–è³ªå•",
                    "trigger": "ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°",
                    "variation": "ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³"
                }}
            ],
            "reflective_questions": [
                {{
                    "question": "å†…çœè³ªå•",
                    "purpose": "ç›®çš„", 
                    "emotional_tone": "æ„Ÿæƒ…çš„ãƒˆãƒ¼ãƒ³"
                }}
            ],
            "strategic_questions": [
                {{
                    "question": "æˆ¦ç•¥çš„è³ªå•",
                    "scope": "æ€è€ƒç¯„å›²",
                    "decision_support": "æ„æ€æ±ºå®šæ”¯æ´ãƒ¬ãƒ™ãƒ«"
                }}
            ],
            "closing_questions": [
                {{
                    "question": "ç· ã‚ããã‚Šè³ªå•",
                    "purpose": "ç›®çš„",
                    "next_action": "æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
                }}
            ]
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯è³ªå•æŠ€è¡“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚åŠ¹æœçš„ã§æˆ¦ç•¥çš„ãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": questions_prompt}
                ],
                temperature=0.4,
                response_format={"type": "json_object"}
            )
            
            questions_data = json.loads(response.choices[0].message.content)
            
            # å…¨ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰è³ªå•ã‚’æŠ½å‡º
            all_questions = []
            for category, questions in questions_data.items():
                for q in questions:
                    all_questions.append(q.get('question', ''))
            
            return all_questions[:10]  # ä¸Šä½10å€‹ã®è³ªå•
            
        except Exception as e:
            print(f"Strategic questions generation error: {e}")
            return [
                f"{topic}ã«ã¤ã„ã¦ã€ã©ã®ã‚ˆã†ãªçµŒé¨“ã‚’ãŠæŒã¡ã§ã™ã‹ï¼Ÿ",
                f"æœ€ã‚‚é‡è¦ã ã¨æ€ã†ç‚¹ã¯ä½•ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
                f"ç†æƒ³çš„ãªçµæœã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ã§ã—ã‚‡ã†ï¼Ÿ"
            ]
    
    async def apply_advanced_dialogue_management(self, user_input: str, context: CommunicationContext,
                                               dialogue_history: List[Dict] = None) -> Dict:
        """é«˜åº¦å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã®é©ç”¨"""
        
        management_prompt = f"""
        é«˜åº¦ãªå¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã‚’é©ç”¨ã—ã¦ã€ä»¥ä¸‹ã®ä¼šè©±ã‚’åˆ†æãƒ»æœ€é©åŒ–ã—ã¦ãã ã•ã„ï¼š
        
        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã€‘{user_input}
        ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆã€‘{context.__dict__}
        ã€å¯¾è©±å±¥æ­´ã€‘{json.dumps(dialogue_history[-5:] if dialogue_history else [], ensure_ascii=False)}
        
        ä»¥ä¸‹ã®JSONå½¢å¼ã§å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        
        {{
            "active_listening": {{
                "key_points_identified": ["ãƒã‚¤ãƒ³ãƒˆ1", "ãƒã‚¤ãƒ³ãƒˆ2"],
                "emotions_detected": ["æ„Ÿæƒ…1", "æ„Ÿæƒ…2"],
                "unstated_concerns": ["æ‡¸å¿µ1", "æ‡¸å¿µ2"],
                "reflection_response": "åæ˜ å¿œç­”"
            }},
            "rapport_building": {{
                "connection_opportunities": ["æ©Ÿä¼š1", "æ©Ÿä¼š2"],
                "shared_experiences": ["å…±é€šä½“é¨“1", "ä½“é¨“2"],
                "trust_building_actions": ["è¡Œå‹•1", "è¡Œå‹•2"],
                "rapport_indicators": ["æŒ‡æ¨™1", "æŒ‡æ¨™2"]
            }},
            "influence_strategy": {{
                "primary_approach": "logic|emotion|authority|social_proof",
                "supporting_evidence": ["æ ¹æ‹ 1", "æ ¹æ‹ 2"],
                "persuasion_sequence": ["ã‚¹ãƒ†ãƒƒãƒ—1", "ã‚¹ãƒ†ãƒƒãƒ—2"],
                "resistance_handling": ["å¯¾å‡¦æ³•1", "å¯¾å‡¦æ³•2"]
            }},
            "engagement_optimization": {{
                "attention_maintainers": ["è¦ç´ 1", "è¦ç´ 2"],
                "curiosity_generators": ["è¦ç´ 1", "è¦ç´ 2"],
                "participation_encouragers": ["æ–¹æ³•1", "æ–¹æ³•2"],
                "energy_level_adjustments": ["èª¿æ•´1", "èª¿æ•´2"]
            }},
            "conversation_steering": {{
                "current_direction": "ç¾åœ¨ã®æ–¹å‘æ€§",
                "optimal_direction": "æœ€é©ãªæ–¹å‘æ€§",
                "transition_strategy": "è»¢æ›æˆ¦ç•¥",
                "milestone_checkpoints": ["ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ1", "ãƒã‚¤ãƒ³ãƒˆ2"]
            }}
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚é«˜åº¦ãªæŠ€è¡“ã‚’é§†ä½¿ã—ã¦åŠ¹æœçš„ãªå¯¾è©±æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": management_prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            print(f"Dialogue management error: {e}")
            return {"error": "Advanced dialogue management unavailable"}
    
    async def generate_master_communication_response(self, user_input: str, context: CommunicationContext,
                                                   explanation_strategy: ExplanationStrategy,
                                                   strategic_questions: List[str],
                                                   dialogue_management: Dict) -> str:
        """ãƒã‚¹ã‚¿ãƒ¼ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚¿ãƒ¼çµ±åˆå¿œç­”ç”Ÿæˆ"""
        
        master_prompt = f"""
        ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ã¨ã—ã¦ã€çµ±åˆçš„ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
        
        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã€‘{user_input}
        ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆã€‘{context.__dict__}
        ã€èª¬æ˜æˆ¦ç•¥ã€‘{explanation_strategy.__dict__}
        ã€æˆ¦ç•¥çš„è³ªå•ã€‘{strategic_questions[:3]}
        ã€å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã€‘{dialogue_management}
        
        ä»¥ä¸‹ã®è¦ç´ ã‚’çµ±åˆã—ãŸæœ€é«˜å“è³ªã®å¿œç­”ã‚’ç”Ÿæˆï¼š
        
        1. ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã€‘- æ·±ã„ç†è§£ã¨å…±æ„Ÿã®è¡¨ç¾
        2. ã€æœ€é©èª¬æ˜ã€‘- æ–‡è„ˆã«å¿œã˜ãŸç†è§£ã—ã‚„ã™ã„èª¬æ˜
        3. ã€æˆ¦ç•¥çš„è³ªå•ã€‘- æ€è€ƒã‚’æ·±ã‚ã‚‹åŠ¹æœçš„ãªå•ã„ã‹ã‘
        4. ã€ãƒ©ãƒãƒ¼ãƒˆæ§‹ç¯‰ã€‘- ä¿¡é ¼é–¢ä¿‚ã®å¼·åŒ–
        5. ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã€‘- èˆˆå‘³ã¨å‚åŠ ã‚’ä¿ƒé€²
        6. ã€å½±éŸ¿åŠ›è¡Œä½¿ã€‘- é©åˆ‡ã§å»ºè¨­çš„ãªèª¬å¾—
        7. ã€ä¼šè©±èª˜å°ã€‘- ç›®æ¨™ã«å‘ã‘ãŸè‡ªç„¶ãªæµã‚Œ
        8. ã€æ„Ÿæƒ…é…æ…®ã€‘- æ„Ÿæƒ…çŠ¶æ…‹ã¸ã®é©åˆ‡ãªå¯¾å¿œ
        
        å¿œç­”æ§‹é€ ï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´ï¼‰ï¼š
        
        ## ğŸ¤ **ç†è§£ã¨å…±æ„Ÿ**
        [ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çŠ¶æ³ãƒ»æ„Ÿæƒ…ã¸ã®æ·±ã„å…±æ„Ÿã¨ç†è§£]
        
        ## ğŸ’¡ **æ´å¯Ÿã¨èª¬æ˜**
        [æœ€é©åŒ–ã•ã‚ŒãŸèª¬æ˜ãƒ»æ´å¯Ÿã®æä¾›]
        
        ## ğŸ” **æ¢æ±‚ã®è³ªå•**
        [æ€è€ƒã‚’æ·±ã‚ã‚‹æˆ¦ç•¥çš„è³ªå•]
        
        ## ğŸš€ **è¡Œå‹•ã¸ã®èª˜å°**
        [å…·ä½“çš„ã§å®Ÿè¡Œã—ã‚„ã™ã„æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—]
        
        æœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¡“ã‚’é§†ä½¿ã—ãŸå¿œç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ Catherine AI ã§ã™ã€‚å…¨ã¦ã®æŠ€è¡“ã‚’çµ±åˆã—ãŸå®Œç’§ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": master_prompt}
                ],
                temperature=0.6,
                max_completion_tokens=2500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Master communication response error: {e}")
            return self._fallback_communication_response(user_input, context)
    
    def _fallback_communication_response(self, user_input: str, context: CommunicationContext) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å¿œç­”"""
        
        empathy_phrases = [
            "ãŠã£ã—ã‚ƒã‚‹ã“ã¨ã€æœ¬å½“ã«ã‚ˆãã‚ã‹ã‚Šã¾ã™ã€‚",
            "ãã®ãŠæ°—æŒã¡ã€ã™ã”ãç†è§£ã§ãã¾ã™ã€‚", 
            "ãªã‚‹ã»ã©ã€ãã†ã„ã†çŠ¶æ³ãªã‚“ã§ã™ã­ã€‚"
        ]
        
        questions = [
            f"ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã›ã‚“ã‹ï¼Ÿ",
            f"ã©ã®ã‚ˆã†ãªçµæœã‚’æœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ",
            f"ä¸€ç•ªå¤§åˆ‡ã«ã—ãŸã„ç‚¹ã¯ä½•ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
        ]
        
        empathy = random.choice(empathy_phrases)
        question = random.choice(questions)
        
        return f"{empathy}\n\n{user_input}ã«ã¤ã„ã¦ã€{question}"

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    import os
    
    async def test_master_communication():
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        communicator = MasterCommunicator(client)
        
        user_input = "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—ãŒé…ã‚Œã¦ã„ã¦ã€ãƒãƒ¼ãƒ ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸‹ãŒã£ã¦ã„ã¾ã™ã€‚ã©ã†ã—ãŸã‚‰ã„ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
        
        # æ–‡è„ˆåˆ†æ
        context = await communicator.analyze_communication_context(user_input)
        print(f"ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–‡è„ˆ: {context}")
        
        # èª¬æ˜æˆ¦ç•¥è¨­è¨ˆ  
        strategy = await communicator.design_optimal_explanation("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã¨ãƒãƒ¼ãƒ å‹•æ©Ÿä»˜ã‘", context, 6)
        print(f"èª¬æ˜æˆ¦ç•¥: {strategy.approach}")
        
        # æˆ¦ç•¥çš„è³ªå•ç”Ÿæˆ
        questions = await communicator.generate_strategic_questions("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ”¹å–„", context, "exploration")
        print(f"æˆ¦ç•¥çš„è³ªå•: {questions[:3]}")
        
        # å¯¾è©±ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ
        dialogue_mgmt = await communicator.apply_advanced_dialogue_management(user_input, context)
        
        # çµ±åˆå¿œç­”ç”Ÿæˆ
        response = await communicator.generate_master_communication_response(
            user_input, context, strategy, questions, dialogue_mgmt
        )
        
        print(f"\n=== ãƒã‚¹ã‚¿ãƒ¼ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚¿ãƒ¼å¿œç­” ===")
        print(response)
    
    asyncio.run(test_master_communication())